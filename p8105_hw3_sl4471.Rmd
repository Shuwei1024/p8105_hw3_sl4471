---
title: "p8105_hw3_sl4471"
author: Shuwei Liu sl4471
date: 10.13.2018
output: github_document
---


```{r setup, include=FALSE}
knitr::opts_chunk$set(
  fig.width = 8,
  fig.asp = 1.5,
  out.width = "90%")
library(tidyverse)
library(ggridges)
library(patchwork)
library(hexbin)
```

# Problem1

## 1.1 Import and Clean the data

```{r import_data1}
devtools::install_github("p8105/p8105.datasets")
library(p8105.datasets)
data("brfss_smart2010")
overall_health_df = 
  janitor::clean_names(brfss_smart2010) %>%
  rename(state = "locationabbr") %>% 
  filter(topic == "Overall Health") %>% 
  mutate(response = factor(response, levels = str_c(
    c("Excellent", "Very good", "Good", "Fair", "Poor"))))
```

## 1.2 In 2002, which states were observed at 7 locations?

```{r 2002_data}
data_2002 = 
  filter(overall_health_df, year == "2002") %>% 
  group_by(state) %>% 
  summarize(n_obs = n(),
            n_loc = n_distinct(locationdesc)) %>% 
  select(state, n_loc) %>% 
  filter(n_loc == "7")
```

In the year 2002, state Connecticut, Florida and North Carolina were observed at 7 locations.

## 1.3 Spaghetti plot

```{r spaghetti, fig.width = 7, fig.asp = 1, out.width = "90%"}
number_locations_df = 
  overall_health_df %>% 
  group_by(state, year) %>% 
  summarise(n_obs = n(), n_loc = n_distinct(locationdesc))
ggplot(number_locations_df, aes(x = year, y = n_loc, color = state)) +
  geom_line() +
  labs(
    title = "Number of locations in each state from 2002 to 2010",
    x = "number of locations",
    y = "year") +
  theme_bw() +
  theme(legend.position = "bottom")
```

I chose "geom_line" for the "spaghetti plot" since we need to show the changes of the number of locations in different states over years. The line plot could not only display the trend for changes of each states but also compare the number of locations between the states. From the plot, we can tell that most of the states have a stable change and some of them did not have a different number of locations over years. Florida has a disctint change of the number.

## 1.4 Table for the proportion of "Excellent" in NY
```{r excellent_in_NY}
NY_data = 
overall_health_df %>% 
  group_by(year) %>%
  filter(state == "NY", response == "Excellent", year %in% c(2002, 2006, 2010)) %>% 
  summarise(excellent_mean = mean(data_value, na.rm =  TRUE), 
            excellent_sd = sd(data_value, na.rm =  TRUE)) %>% 
  knitr::kable(digits = 1)
NY_data
```

From above, the mean of the proportion of "Excellent" response has decreased from 24% to 22.7%. However, the standard deviation of it also decreased which means that the range of the data for 2010 is smaller then the range of that for 2002. 

## 1.5 The distribution of state-level averages over time

```{r average_distribution, fig.width = 7, fig.asp = 1.5, out.width = "90%"}
avearge_proportion_df = 
  overall_health_df %>% 
  group_by(state, year, response) %>%
  summarise(mean = mean(data_value, na.rm = TRUE))
ggplot(avearge_proportion_df, aes(x = year, y = mean, color = state)) +
  geom_line() +
  facet_grid(~response) +
  labs(
    title = "State-level average of response VS year",
    x = "Year",
    y = "Average proportion",
    caption = "Data from p8105.datasets") +
  theme_bw() +
  theme(legend.position = "bottom") +
  theme(axis.text.x = element_text(angle = 45))
```
 
Each state has fairly same average proportion for each response. The "Very good" Response has the highest proportion while the "Poor" response has the least. 

## Problem2

## 2.1 Description of dataset


```{r import_data2}
data("instacart")
str(instacart)
dim(instacart)
```

We can use "str()" and "dim" to look through the dataset. This a "tbl_df" data with 1384617 rows and 15 columns. It includes "order_id", "product_id", "add_to_cart_order", "reordered", "user_id", "eval_set", "order_number", "order_dow", "order_hour_of_day", "days_since_prior_order", "product_name", "aisle_id", "department_id", "aisle" and "department" variables. Basically, it tells us "who" order "what" kind of product under "which" aisle and department if it is reordered or not. To be specific, just take the first row as an example, the order id "1" shows that  customer "112108" reordered "Bulgarian Yogurt" whose id is "49302" under the yogurt aisle whose id is "120" from the "dairy eggs" department whose id is "16" at 10am on Thursday as this customers first order this time. This order was 9 days after since the customer's last one.

```{r number_of_aisles}
count(distinct(instacart, aisle))
instacart %>% 
  janitor::clean_names() %>% 
  group_by(aisle) %>% 
  summarize(n_obs = n()) %>% 
  arrange(desc(n_obs))
```

There are 134 aisles and "fresh vegetables" is the most items ordered from.

## 2.2 The number of items ordered in each aisle

```{r number_of_items1}
instacart %>% 
  group_by(aisle) %>% 
  ggplot(aes(x = aisle, fill = department)) +
  geom_bar(width = 1) +
  labs(
    title = "Number of product ordered",
    x = "aisle name",
    y = "number of product ordered") +
  theme_bw() +
  theme(legend.position = "bottom") +
  theme(axis.text.x = element_text(size = 6, angle = 90, hjust = 1))
```

The range of the number of product is so large that it cannot be displayed readable in a plot. So I separate it into 6 plot by different aisle id.

```{r: number_of_items2, fig.width = 9, fig.asp = 1.5, out.width = "90%"}
number_product_1 =
  instacart %>% 
  group_by(aisle_id) %>% 
  filter(aisle_id <= 23) %>% 
  ggplot(aes(x = aisle_id)) +
  geom_histogram() +
  labs(
    title = "Number of product ordered(aisle_id = 1-23)",
    x = "aisle id",
    y = "number of product ordered") +
  theme_bw() 

number_product_2 =
  instacart %>% 
  group_by(aisle_id) %>% 
  filter(aisle_id <= 46, aisle_id > 23) %>% 
  ggplot(aes(x = aisle_id)) +
  geom_histogram() +
  labs(
    title = "Number of product ordered(aisle_id = 24-46)",
    x = "aisle id",
    y = "number of product ordered") +
  theme_bw() 

number_product_3 =
  instacart %>% 
  group_by(aisle_id) %>% 
  filter(aisle_id <= 69, aisle_id > 46) %>% 
  ggplot(aes(x = aisle_id)) +
  geom_histogram() +
  labs(
    title = "Number of product ordered(aisle_id = 47-69)",
    x = "aisle id",
    y = "number of product ordered") +
  theme_bw() 

number_product_4 =
  instacart %>% 
  group_by(aisle_id) %>% 
  filter(aisle_id <= 92, aisle_id > 69) %>% 
  ggplot(aes(x = aisle_id)) +
  geom_histogram() +
  labs(
    title = "Number of product ordered(aisle_id = 70-92)",
    x = "aisle id",
    y = "number of product ordered") +
  theme_bw() 

number_product_5 =
  instacart %>% 
  group_by(aisle_id) %>% 
  filter(aisle_id <= 115 , aisle_id > 92) %>% 
  ggplot(aes(x = aisle_id)) +
  geom_histogram() +
  labs(
    title = "Number of product ordered(aisle_id = 93-115)",
    x = "aisle id",
    y = "number of product ordered") +
  theme_bw() 

number_product_6 =
  instacart %>% 
  group_by(aisle_id) %>% 
  filter(aisle_id <= 134, aisle_id > 115) %>% 
  ggplot(aes(x = aisle_id)) +
  geom_histogram() +
  labs(
    title = "Number of product ordered(aisle_id = 115-134)",
    x = "aisle id",
    y = "number of product ordered") +
  scale_x_continuous(
    breaks = c(115, 120, 125, 130, 135),
    labels = c("115", "120", "125", "130", "135")
  ) +
  theme_bw() 

(number_product_1 + number_product_2) / (number_product_3 + number_product_4) / (number_product_5 + number_product_6)
```

## 2.3  Table of the most popular item 

```{r most_popular_item}
instacart %>% 
  filter(aisle %in% c("baking ingredients", "dog food care", "packaged vegetables fruits")) %>% 
  group_by(aisle, product_name) %>% 
  summarize(n_product = n()) %>% 
  filter(min_rank(desc(n_product)) == 1) %>% 
  select(aisle, product_name) %>% 
  knitr::kable(digits = 1)
```

From the table, the most popular item of "baking ingredients" is "Light Brown Sugar". "Snack Sticks Chicken & Rice Recipe Dog Treats" and "Organic Baby Spinash" are the most popular items of "dog food care" and "packaged vegetables fruits" respectively.

## 2.4 Table of the mean hour of the day

```{r mean_hour}
instacart %>% 
  filter(product_name == "Pink Lady Apples" | product_name == "Coffee Ice Cream") %>% 
  group_by(product_name, order_dow) %>% 
  summarize(hours_mean = mean(order_hour_of_day, na.rm = TRUE)) %>% 
  spread(key = order_dow, value = hours_mean) %>%
  rename('Sun.' = '0', 'Mon.' = '1', 'Tue.' = '2', 
         'Wed.' = '3', 'Thu.' = '4', 'Fri.' = '5', 'Sat.' = '6') %>% 
  knitr::kable(digits = 1)
```

# Problem 3

## 3.1 Description of dataset

```{r import_data3}
data("ny_noaa")
str(ny_noaa)
dim(ny_noaa)
```

This "ny_noaa" dataset includes weather data from all New York state weather stations between 1981 and 2010. It is a "tbl_df" dataset with 2595176 rows * 7 columns. It contains 7 variables which is "id", "date", "prcp", "snow", "snwd", "tmax" and "tmin" where "prcp" stands for precipitation with unit "tenths of mm", "snow" stands for snowfall with unit "mm", "snwd" stands for snow depth with unit "mm", "tmax" stands for maximum temperature with unit "tenths of degrees C", "tmin" stands for minimum temperature with unit "tenths of degrees C". 

## 3.2 Data cleaning

```{r data_cleaning}
ny_noaa_tidy = 
  ny_noaa %>%
  janitor::clean_names() %>% 
  separate(date, into = c("year", "month", "date"), sep = "-") %>%
  mutate(prcp = as.numeric(prcp)/10, tmax = as.numeric(tmax)/10, tmin = as.numeric(tmin)/10)
ny_noaa_tidy %>% 
  group_by(snow) %>% 
  summarize(n = n()) %>% 
  arrange(desc(n))
```

Because the unit of "prcp" is "tenths of mm", the units of "tmax" and "tmin" are  "tenths of degrees C", I change the unit more reasonable. 

The most commonly observed value of snowfall is 0. Snowfall only takes place in winter, so for the most time of a year it would not happen.

## 3.3 The plots

### 3.3.1

```{r average_max_temperature, fig.width = 6, fig.asp = 1, out.width = "90%"}
ny_noaa_meantmax = 
  ny_noaa_tidy %>% 
  select(id, year, month, tmax) %>% 
  filter(month %in% c("01", "07")) %>% 
  mutate(month = recode(month, `01` = "January", `07` = "July")) %>% 
  group_by(id, year, month) %>% 
  summarize(tmax_mean = mean(tmax, na.rm = TRUE))

ggplot(ny_noaa_meantmax, aes(x = year, y = tmax_mean)) +
  geom_boxplot() +
  facet_grid(~month) +
  labs(
    title = "The average max temperature in January and in July across years",
    x = "Year", 
    y = "The average max temperature(ºC)",
    caption = "Data from the p8105.datasets"
  ) +
  theme_bw() +
  theme(axis.text.x = element_text(size = 5, angle = 45))
```

We can use "boxplot.stats()" function to check the outliers.

```{r outlier}
ny_noaa_meantmax %>%
  filter(month == "January") %>% 
  .$tmax_mean %>% 
  boxplot.stats()

ny_noaa_meantmax %>%
  filter(month == "July") %>% 
  .$tmax_mean %>% 
  boxplot.stats()
```

From the plot, we can compare the average of max temperature on January with that on July across years. We the tell the basic descripttive data of each including range, Q1, median, Q3.


### 3.3.2

```{r two_panel_plot}
tmax_tmin = 
  ggplot(ny_noaa_tidy, aes(x = tmax, y = tmin)) + 
  geom_hex() +
  labs(
    title = "tmax VS tmin for the full dataset",
    x = "Maxiumum daily temperature (ºC)",
    y = "Minimum daily temperature (ºC)",
    caption = "Data from the p8105.datasets"
  ) +
  viridis::scale_color_viridis(discrete = TRUE) +
  theme_bw() +
  theme(legend.position = "right") 

distribution_snow =
  ny_noaa_tidy %>% 
  filter(snow > 0, snow < 100) %>% 
  ggplot(aes(x = snow, fill = year)) + 
  geom_density(alpha = .4, adjust = .4, color = "blue") +
  labs(
    title = "The distribution of snowfall values greater than 0 and less than 100",
    x = "Snowfall value",
    y = "Density",
    caption = "Data from the p8105.datasets"
  ) +
  theme_bw() +
  theme(legend.position = "bottom") +
  theme(axis.text.x = element_text(angle = 45))

(tmax_tmin)/(distribution_snow)
```

I chose "geom_hex" for the first plot since it could show the highest frequency values which is the light blue part on the plot. And I chose "geom_density" to show the distribution of snowfall values greater than 0 and less than 100. Boxplot is easier to compare the distribution over years and can easily identify the outliers.
